---
title: "Midterm In Class Portion"
author: "Grace Wysocki"
date: "3/9/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Complete this exam in a .Rmd file. To turn in the exam, push both a .Rmd file and a knitted .html file to your GitHub site.

Statement of Integrity: Copy and paste the following statement and then sign your name (by typing it) on the line below.

“All work presented is my own. I have not communicated with or worked with anyone else on this exam.”

Grace Wysocki

Collaboration Reminder: You may not communicate with or work with anyone else on this exam, but you may use any of our course materials or materials on the Internet.



Question 1 (20 points). Examine the following plot that uses the pokemon_full.csv data set. The plot gives the count of each Pokemon type.
```{r}
library(tidyverse)
library(here)
pokemon_df <- read_csv(here("data/pokemon_full.csv"))
pokemon_type <- pokemon_df %>% group_by(Type) %>% summarise(type_count = n())

ggplot(data = pokemon_type, aes(x = Type, y = type_count)) +
  geom_bar(stat = "identity") +
  labs(x = "Type",
       y = "Count") +
  coord_flip()
```

part a. Which of the 7 grammar of graphics parameters are explicitly specified in the code to make the plot?
- <DATA>
- <GEOM_FUNCTION
- <COORDINATE_FUNCTION>
- <STAT>
- <MAPPING>
part b. For these types of plots, we have usually reordered the Type so that the type with the most Pokemon would be first and the type with the least number of pokemon would be last. Use a principle from the Data Visualization Reading to explain why we would want to do this.

Graphs can be confusing or misleading because of how people perceive and process what they are looking at. When a graph is not organized in a way that is appealing to the eye or organized in a way that would confuse the viewer, we would call that in bad taste. This graph would be considered in bad taste because the bars in the graph are not organized in a way that is easy to read and allows for easy comparisons.

part c. We have also stated that, for bar plots and lollipop plots, 0 should be included in the plot. On the other hand, for point plots and scatterplots, 0 need not be included. Using a principle from the Data Visualization Reading, explain why it is okay to omit 0 from a point plot but not from a bar plot.  

It is okay to omit 0 from a point plot because point plots usually have two numerical values that create the point and do not need a relative line/axis to dertermine its value, where are a bar plot starts at zero and goes up, or down if you are being fancy with the graph. You need a relative point to be able to make accurtae comparisons of data. Excluding zero can create misleading scales of data for bar graphs, while it would not effect a point plot in the same way.

Question 2 (5 points). These points will be given for properly committing and pushing a .Rmd and a .html file with your exam answers.

Question 3 (5 points). Tell me something you learned about ethics in data visualization.

One thing I learned was the impartance of making sure that the way you display your data graphically is not dehumanizing. When data points represent say child deaths in school shootings in the United States, you do not want to group deaths by area into counts, rather plotting individual deaths humanizes the data and draws emotion into the image you are creating.

Question 4 (20 points).

part a. A data set on United States election results was obtained from https://github.com/kjhealy/us_elections_2020_csv. Use the maps package, as well as this data set (posted on Sakai), to construct a map that fills each U.S. State with the percent of voters who voted for the republican candidate, Trump (percent_gop). For this problem,

you do not need to worry about including Alaska or Hawaii. They are important but this is a timed exam!
you should change the colour scale so that it is appropriate for the problem.
```{r}
library(maps)
library(tidyverse)
library(here)
election_df <- read_csv(here("data/2020_county_pres.csv")) %>%
  group_by(state_name) %>%
  summarise(total_gop = sum(votes_gop),
            total_dem = sum(votes_dem)) %>%
  mutate(percent_gop = 100 * total_gop / (total_gop + total_dem)) %>%
  mutate(state_name = str_to_lower(state_name))
#view(election_df)

state_df <- ggplot2::map_data("state")
#view(state_df)

ggplot(data = state_df,
            mapping = aes(x = long, y = lat,
                          group = group)) +
  geom_polygon() 
```

```{r}
state_votes <- election_df %>% mutate(state = str_to_lower(state_name))
state_full <- left_join(state_df, state_votes, by = c("region" = "state"))

ggplot(data = state_full, aes(x = long, y = lat, group = group)) +
  geom_polygon(colour = "black", aes(fill = percent_gop)) +
  coord_map(projection = "albers", lat0 = 39, lat1 = 45) +
  theme_void() +
  scale_fill_viridis_c()
```

part b. Explain why the data frame R needs to construct a map of the United States is much, much longer than 50 rows.

It needs it because it contains all of the information necessary for R to draw the polygonal shapes of each state. It needs a lot of information to be able to map our all of the individual borders of each state and the country.

Question 5 (25 points). Construct a shiny app using the alcohol.csv data set that has a scatterplot of the number of wine servings vs. the number of beer servings. In the app, the user should be able to select a country and have a label for that country appear on the app.

In addition, create an input that lets the user choose a variable (either beer_servings, spirit_servings, and wine_servings) and create an output that is a histogram based on that variable.

So you can focus your time on shiny as much as possible, a static graph or wine servings vs. beer servings, with Australia labeled, is given below (you may copy this code to use in your app if you would like).

You must complete this task using shiny (even though you could do something similar using plotly).
```{r}
library(shiny)
library(tidyverse)
library(ggrepel)
library(here)
alcohol_df <- read_csv(here("data/alcohol.csv"))

onecountry_df <- alcohol_df %>% filter(country == "Australia")

ggplot(alcohol_df, aes(x = beer_servings, y = wine_servings)) +
  geom_point() +
  geom_label_repel(data = onecountry_df, aes(label = country)) +
  geom_point(data = onecountry_df, size = 3, shape = 1)
```

Question 6 (10 points). For the following shiny app, draw a reactive graph. I think the easiest way to do this would be to hand-draw the graph and hand it in on a piece of paper (there is paper at the front of the room). If you can figure out a way to draw it on your computer, you may do that and push that file to GitHub.

(see piece of paper)

Question 7 (20 points). Consider again the women’s tennis data set, wta_matches_2019.csv, where each row corresponds to a match played on the WTA (Women’s Tennis Association) tour. Important variables to consider for this problem include:

winner_name, the name of the player who won the match
loser_name, the name of the player who lost the match
Construct a lollipop chart that shows the 10 WTA tennis players with the highest average number of aces in the 2019 season who have played at least 20 matches.

Some Hints:

if you can’t complete the task, make a lollipop chart of something to earn some partial credit.
variables that you will need are winner_name, loser_name, w_ace, and l_ace.
we haven’t done much in tidyr in class so I’ve already pivoted the data set for you (see code below).
you will need to create a new variable called aces that is the w_ace if the player won (so if won_or_lost is winner_name) and l_ace if the player lost.
recall that, if there are missing values, you will need to remove them when finding the mean aces for a player. You can do this with the na.rm = TRUE argument to your summarise() function. See https://highamm.github.io/datascience234/dplyr.html#removing-missing-values for a quick review of this.
you will also need to count up the matches for each player and use a filtering join to only keep players who have played 20 or matches. As I’m writing this, I am realizing we did not do a ton with joins….so here is some code that may be helpful: semi_join(data_set_with_players_and_mean_aces, data_set_with_players_with_20_matches_or_more, by = c("player" = "player"))
```{r}
library(tidyverse)
library(here)
wta_df <- read_csv(here("data/wta_matches_2019.csv"))
view(wta_df)

df <- wta_df %>% filter(tourney_name == "Australian Open") %>% group_by(winner_name, w_ace) %>% summarise(total_w_ace = sum(w_ace)) %>% arrange(desc(w_ace)) %>% filter(w_ace > 10)

view(df)                                                                                                          
```

```{r}
ggplot(data = df, aes(x = winner_name, y = w_ace)) +
  geom_point() + 
  geom_segment(aes(x = winner_name, xend = winner_name, y = 0, yend = w_ace)) +
  coord_flip() +
  labs(x = "Winner Name", 
       y = "Number of Winning Aces")
```

Question 8 (20 points).

part a. Consider the lollipop plot you made in Question 7. Why is this plot not the best plot to make to look at the top women’s servers in 2019? (There might be a couple of reasons but you should reference one that we have explicitly talked about in class a lot).

This graph would noy be good because it may show who has the most winning aces, but it does not show the variability of their service. A player may be the type to either ace someone, or double fault so it is important to look at the variabilty of their service.

part b. Fix the plot so that it no longer has the issue you described in Question 8a. If you could not make the plot in Question 7, use this much simpler data set to plot the mean of yvar for each group and then fix the issue.
```{r}
library(tibble)
set.seed(03092022)
toy_df <- tibble(group = c("a", "a", "a", "b", "b", "b", "c", "c",
                           "c", "c", "d", "d"),
       response = rnorm(12, 4, 3))
#ggplot(data = toy_df, mapping = aes(x = group, y = qnorm)) +
  #geom_point()
```